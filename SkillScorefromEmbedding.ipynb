{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dml--FMCt6Vx",
        "outputId": "423f11d4-d79a-4019-82fd-8d35540343b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.238-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting InstructorEmbedding\n",
            "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.18)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.13-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
            "  Downloading langsmith-0.0.12-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=853bb17c35a9abaf97e080e30edff5693211f4dbcea21725a6466eca854df34a\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, InstructorEmbedding, faiss-cpu, mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langsmith, huggingface-hub, transformers, openai, dataclasses-json, langchain, sentence_transformers\n",
            "Successfully installed InstructorEmbedding-1.0.1 dataclasses-json-0.5.13 faiss-cpu-1.7.4 huggingface-hub-0.16.4 langchain-0.0.238 langsmith-0.0.12 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 safetensors-0.3.1 sentence_transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.31.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai faiss-cpu InstructorEmbedding sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Earlier I used these\n",
        "# !tiktoken pypdf panel"
      ],
      "metadata": {
        "id": "PLjFMBQ5ubW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5SAQQmGNW9F",
        "outputId": "e045ff55-6342-44ab-b49a-19ebb61dbec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "MxPYldauxVBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imports and standard loading\n",
        "from google.colab import drive\n",
        "import os\n",
        "# Vector Store\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Choice of LLM\n",
        "import json\n",
        "import pprint\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "#QA Chains\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import RetrievalQA\n",
        "# Intelligence Chains\n",
        "from langchain import LLMChain\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "OPENAI_API_KEY = \"your-key-here\"\n",
        "\n",
        "def read_a_random_resume(main_folder_path,idx):\n",
        "  candidates_embedding_path = os.path.join(main_folder_path,\"candidates_embedding\")\n",
        "  choice = \"Instruct\"\n",
        "  if choice==\"OpenAI\":\n",
        "    from langchain.embeddings import OpenAIEmbeddings\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "  elif choice==\"Instruct\":\n",
        "    from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "    embeddings = HuggingFaceInstructEmbeddings()\n",
        "  all_candidates = os.listdir(candidates_embedding_path)\n",
        "  someone = all_candidates[idx]\n",
        "  db = FAISS.load_local(os.path.join(candidates_embedding_path,someone), embeddings)\n",
        "  return db\n",
        "\n",
        "db = read_a_random_resume(main_folder_path=\"/content/drive/MyDrive/Resume Ranking\",idx=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "yyKkjZ-M6nh5",
        "outputId": "7d742566-34cf-418f-d726-9df6dd554995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c4e1408f054d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Vector Store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Choice of LLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field, validator\n",
        "from typing import List, Dict, Set"
      ],
      "metadata": {
        "id": "JK55ml1eGnTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def get_top_level_details_from_candidate(Check_role):\n",
        "  global db\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"OTHER_SUITABLE_ROLES\": list // A list of all other suitable roles\n",
        "    \"TOP_SUITABLE_ROLES\": key value pair // The best suitable role and score for that role out of 100\n",
        "    \"RECENT_DESIGNATION\": string // What is most recent designation\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "  )\n",
        "  chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "  query=\"\"\"\n",
        "        what are the other suitable roles for him\n",
        "        What is the top best suitable role for him along with score\n",
        "        What is his most recent designation\n",
        "        \"\"\"\n",
        "\n",
        "  result = qa.run(query)\n",
        "  if \"```json\" in result:\n",
        "    print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  pprint.pprint(structured_output)\n",
        "  return structured_output\n",
        "\n",
        "def get_top_level_details_from_GPT(Check_role,skill_list):\n",
        "  global db\n",
        "  prompt_template = \"\"\"\n",
        "  {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"SCORE_FOR_\"\"\"+Check_role.upper().replace(\" \",\"_\")+\"\"\"\": string  // scoring for the candidate for \"\"\"+Check_role+\"\"\" profile out of 100 based on the skill set given\n",
        "    \"OTHER_SUITABLE_ROLES\": key value pair // A key value pair of all other suitable roles based on skill set and score out of 100 for each\n",
        "    \"TOP_SUITABLE_ROLES\": key value pair // The best suitable role and score for that role out of 100\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"question\"]\n",
        "  )\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  llm_chain = LLMChain(prompt=PROMPT, llm=choice_of_llm)\n",
        "  query=\"\"\"Based on all the skills the candidate has give scoring for the candidate for the role of \"\"\"+Check_role+\"\"\"\n",
        "        Based on his skillset what are the other suitable roles for him along with score for each\n",
        "        What is the top best suitable role for him along with score\n",
        "        Skill set : \"\"\"+\",\\n\".join(skill_list)+\"\"\"\n",
        "        \"\"\"\n",
        "\n",
        "  result = llm_chain.run(query)\n",
        "  if \"```json\" in result:\n",
        "    #print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    #print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  pprint.pprint(structured_output)\n",
        "  return structured_output\n",
        "\n",
        "def is_downgrade(chosen_llm, given_role, top_role):\n",
        "  template = \"\"\" on a scale of 0 to 10 on corporate hierarchy where would a {given_role} and {top_role} be\n",
        "  also give reason for difference if there is a difference\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"\"\"\"\"+given_role.upper().replace(\" \",\"_\")+\"\"\"\"\": int range(0-10) // yes or no indicating if the given designation 1 is a downgrade\n",
        "    \"\"\"\"\"+top_role.upper().replace(\" \",\"_\")+\"\"\"\"\": int range(0-10) // if downgrade provide reasons why if not answer None\n",
        "    \"REASONS\": string // If \"\"\"+top_role+\"\"\" is ranked higher then \"\"\"+given_role+\"\"\" explain why else answer None\n",
        "  }}\"\"\"\n",
        "\n",
        "  prompt = PromptTemplate(template=template, input_variables=[\"given_role\",\"top_role\"])\n",
        "  intelligent_llm_chain = LLMChain(prompt=prompt, llm=chosen_llm)\n",
        "  result_2 = intelligent_llm_chain.run({\"given_role\":given_role,\"top_role\":top_role})\n",
        "  #print(result_2)\n",
        "  if \"```json\" in result_2:\n",
        "    print(\"formatting downgrade\")\n",
        "    json_string_2 = result_2.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    #print(json_string_2)\n",
        "    structured_output_2=json.loads(json_string_2)\n",
        "    if int(structured_output_2[top_role.upper().replace(\" \",\"_\")]) > int(structured_output_2[given_role.upper().replace(\" \",\"_\")]):\n",
        "      structured_output_2[\"IS_DOWNGRADE\"] = \"Yes\"\n",
        "    else:\n",
        "      structured_output_2[\"IS_DOWNGRADE\"] = \"No\"\n",
        "    return structured_output_2\n",
        "  else:\n",
        "    print(\"Issue\")\n",
        "    json_string_2 = result_2\n",
        "    return json_string_2\n",
        "\n",
        "def get_all_skills_terms(given_role):\n",
        "  global db\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"SOFTWARE_SKILLS\": List[Str] // A List of all software terms available\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "  )\n",
        "  chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "  query=\"\"\"\n",
        "        what are all the software terms we can find with respect to \"\"\"+given_role+\"\"\"\n",
        "        \"\"\"\n",
        "  result = qa.run(query)\n",
        "  #print(result)\n",
        "  #print(type(result))\n",
        "  if \"```json\" in result:\n",
        "    #print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    #print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  #pprint.pprint(structured_output)\n",
        "  return list(set(structured_output[\"SOFTWARE_SKILLS\"]))\n",
        "\n",
        "def get_all_skills_experience(given_role, skill_list):\n",
        "  global db\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"\"skill\"\" : str // A key value pair of all skills and their experience\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  #  in float format\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "  )\n",
        "  chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "  query=\"\"\"\n",
        "        For all the software terms given find the years of experience for each if not available give \"NA\"\n",
        "        [\"\"\"+\",\\n\".join(skill_list)+\"\"\"]\n",
        "\n",
        "        \"\"\"\n",
        "        #as float 0.123\n",
        "  #print(query)\n",
        "  result = qa.run(query)\n",
        "  #print(result)\n",
        "  #print(type(result))\n",
        "  if \"```json\" in result:\n",
        "    #print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    #print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  #pprint.pprint(structured_output)\n",
        "  return structured_output\n",
        "\n",
        "def get_skill_categorization(skill_list,industry=\"Software\"):\n",
        "  global db\n",
        "  prompt_template = \"\"\"\n",
        "  {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    //output Answer Here\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"question\"]\n",
        "  )\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  llm_chain = LLMChain(prompt=PROMPT, llm=choice_of_llm)\n",
        "  query=\"\"\"classify the following into \"\"\"+industry+\"\"\" industry related buckets and use as many buckets as possible.\n",
        "  \"\"\"+\",\\n\".join(skill_list)+\"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  result = llm_chain.run(query)\n",
        "  if \"```json\" in result:\n",
        "    #print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    #print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  #pprint.pprint(structured_output)\n",
        "  return structured_output\n",
        "\n",
        "def total_months(daterange):\n",
        "# assigning months to numbers\n",
        "  months = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6, 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12,\n",
        "            'january':1, 'february':2, 'march':3, 'april':4, 'may':5, 'june':6, 'july':7, 'august':8, 'september':9, 'october':10, 'november':11, 'december':12,\n",
        "            'sept':9}\n",
        "\n",
        "# getting the two dates\n",
        "  start_date = daterange.split(' to ')[0].strip().lower()\n",
        "  end_date = daterange.split(' to ')[1].strip().lower()\n",
        "\n",
        "# convert the dates to number and subtract them\n",
        "  start_month = months[start_date.split(' ')[0].lower()]\n",
        "  start_year = int(start_date.split(' ')[1])\n",
        "  end_month = months[end_date.split(' ')[0].lower()]\n",
        "  end_year = int(end_date.split(' ')[1])\n",
        "\n",
        "  diff_years = end_year - start_year\n",
        "  diff_month = end_month - start_month\n",
        "  total_months = (diff_years*12)+diff_month\n",
        "  return total_months\n",
        "\n",
        "def format_year_month(x):\n",
        "    y = x // 12\n",
        "    m = x % 12\n",
        "    return str(y)+ 'y-' + str(m) + 'm'\n",
        "\n",
        "def skills_organizer(given_role,industry=\"Software\"):\n",
        "  final = {}\n",
        "  All_software_skills = get_all_skills_terms(given_role)\n",
        "  print(\"Skills Obtained\")\n",
        "  ##############\n",
        "  candidate_fitness_1 = get_top_level_details_from_GPT(given_role,All_software_skills)\n",
        "  print(\"\\n\\nFITNESS EVALUATED\")\n",
        "  candidate_fitness_2 = get_top_level_details_from_candidate(given_role)\n",
        "  print(\"\\n\\nGETTING HIS DESIGNATIONS EVALUATED\")\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  downgrade_check = is_downgrade(chosen_llm=choice_of_llm, given_role=given_role, top_role=candidate_fitness_2[\"RECENT_DESIGNATION\"])\n",
        "  ##############\n",
        "  SKILL_CATEGORIES = get_skill_categorization(All_software_skills,industry)\n",
        "  print(\"skills categories obtained\")\n",
        "  skill_with_years = {}\n",
        "  for i in range(0,math.ceil(len(All_software_skills)/5)):\n",
        "    if i+(5*i) != len(All_software_skills):\n",
        "      #print(i*10,10*(i+1))\n",
        "      #print(All_software_skills[i*10:10*(i+1)])\n",
        "      result = get_all_skills_experience(given_role,All_software_skills[i*5:5*(i+1)])\n",
        "    else:\n",
        "      #print(i*10,i+(10*i))\n",
        "      #print(All_software_skills[i*10:i+(10*i)])\n",
        "      result = get_all_skills_experience(given_role,All_software_skills[i*5:i+(5*i)])\n",
        "    for k in result.keys():\n",
        "      skill_with_years[k] = result[k]\n",
        "  #result = get_all_skills_experience(\"Java developer\")\n",
        "  temp_fin = {}\n",
        "\n",
        "  for key in skill_with_years.keys():\n",
        "    if skill_with_years[key] != \"NA\":\n",
        "      ##temp_fin[key] = []\n",
        "      temp = skill_with_years[key].split(\",\")\n",
        "      total = 0\n",
        "      for dat_range in temp:\n",
        "        #print(dat_range,\" : \",total_months(dat_range))\n",
        "        total = total + total_months(dat_range)\n",
        "      ##temp_fin[key].append(total_months(dat_range))\n",
        "      temp_fin[key] = format_year_month(total)\n",
        "  print(\"skills with years obtained\")\n",
        "\n",
        "  exp_cat = {}\n",
        "  for cat in SKILL_CATEGORIES.keys():\n",
        "    exp_cat[cat] = {}\n",
        "    for vals in SKILL_CATEGORIES[cat]:\n",
        "      try:\n",
        "        exp_cat[cat][vals] = temp_fin[vals]\n",
        "      except KeyError:\n",
        "        exp_cat[cat][vals] = \"NA\"\n",
        "\n",
        "  final[\"TOP_LEVEL\"] = candidate_fitness_1.copy()\n",
        "  final[\"TOP_LEVEL_2\"] = candidate_fitness_2.copy()\n",
        "  final[\"SKILLS\"] = exp_cat.copy()\n",
        "  final[\"DOWNGRADE_CHECK\"] = downgrade_check.copy()\n",
        "  return final\n"
      ],
      "metadata": {
        "id": "gDuALeWbu7m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_tree = skills_organizer(\"Java developer\",\"Software\")\n",
        "pprint.pprint(skill_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ilN8gaC8DOl",
        "outputId": "cb5400eb-7c72-4ca5-ec63-2dba550bbece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skills Obtained\n",
            "{'OTHER_SUITABLE_ROLES': {'Backend Developer': '90',\n",
            "                          'Frontend Developer': '80',\n",
            "                          'Full Stack Developer': '90',\n",
            "                          'Software Engineer': '85'},\n",
            " 'SCORE_FOR_JAVA_DEVELOPER': '90',\n",
            " 'TOP_SUITABLE_ROLES': {'Full Stack Developer': '90'}}\n",
            "\n",
            "\n",
            "FITNESS EVALUATED\n",
            "formatting\n",
            "{\n",
            "    \"OTHER_SUITABLE_ROLES\": [\"Technical Lead\", \"Module Lead\", \"Technology Consultant\", \"Architect\"],\n",
            "    \"TOP_SUITABLE_ROLES\": {\"Architect\": 100},\n",
            "    \"RECENT_DESIGNATION\": \"Architect\"\n",
            "}\n",
            "\n",
            "{'OTHER_SUITABLE_ROLES': ['Technical Lead',\n",
            "                          'Module Lead',\n",
            "                          'Technology Consultant',\n",
            "                          'Architect'],\n",
            " 'RECENT_DESIGNATION': 'Architect',\n",
            " 'TOP_SUITABLE_ROLES': {'Architect': 100}}\n",
            "\n",
            "\n",
            "GETTING HIS DESIGNATIONS EVALUATED\n",
            "formatting downgrade\n",
            "skills categories obtained\n",
            "skills with years obtained\n",
            "{'DOWNGRADE_CHECK': {'ARCHITECT': 9,\n",
            "                     'IS_DOWNGRADE': 'Yes',\n",
            "                     'JAVA_DEVELOPER': 8,\n",
            "                     'REASONS': 'Architects typically have more experience and '\n",
            "                                'knowledge than Java developers, and are '\n",
            "                                'responsible for overseeing the development '\n",
            "                                'process and making high-level decisions.'},\n",
            " 'SKILLS': {'Build Automation': {'Go Pipelines': 'NA',\n",
            "                                 'Gradle': 'NA',\n",
            "                                 'Jenkins': 'NA'},\n",
            "            'Cloud Platforms': {'Cloudhub': 'NA', 'PCF': 'NA'},\n",
            "            'Databases': {'DB2': 'NA',\n",
            "                          'DB2 Stored Procedures': '0y-4m',\n",
            "                          'Oracle': '0y-7m'},\n",
            "            'ERP': {'Peoplesoft': 'NA'},\n",
            "            'Front-end Frameworks': {'AngularJS': '1y-7m'},\n",
            "            'Integration Platforms': {'Anypoint studio 7.6': 'NA',\n",
            "                                      'Mule 3x/4x': 'NA'},\n",
            "            'Java EE': {'EJB': '0y-8m'},\n",
            "            'Java Frameworks': {'Ajax': '1y-0m',\n",
            "                                'Ford framework for Java': '0y-8m',\n",
            "                                'JSF 2.0': 'NA',\n",
            "                                'Spring Boot': 'NA',\n",
            "                                'Struts': '1y-0m'},\n",
            "            'Java Persistence': {'Hibernate': '0y-7m',\n",
            "                                 'JPA': '1y-4m',\n",
            "                                 'iBatis': 'NA'},\n",
            "            'Static Code Analysis': {'FindBugs': '1y-0m',\n",
            "                                     'SonarQube': '1y-7m',\n",
            "                                     'Sonargraph': 'NA'},\n",
            "            'Version Control': {'Github': '1y-7m'},\n",
            "            'Web Content Management': {'WCS 11.1.8': '1y-0m'},\n",
            "            'Web Services': {'REST/JSON Web services': '1y-4m',\n",
            "                             'SOAP/REST Web service': '2y-6m'}},\n",
            " 'TOP_LEVEL': {'OTHER_SUITABLE_ROLES': {'Backend Developer': '90',\n",
            "                                        'Frontend Developer': '80',\n",
            "                                        'Full Stack Developer': '90',\n",
            "                                        'Software Engineer': '85'},\n",
            "               'SCORE_FOR_JAVA_DEVELOPER': '90',\n",
            "               'TOP_SUITABLE_ROLES': {'Full Stack Developer': '90'}},\n",
            " 'TOP_LEVEL_2': {'OTHER_SUITABLE_ROLES': ['Technical Lead',\n",
            "                                          'Module Lead',\n",
            "                                          'Technology Consultant',\n",
            "                                          'Architect'],\n",
            "                 'RECENT_DESIGNATION': 'Architect',\n",
            "                 'TOP_SUITABLE_ROLES': {'Architect': 100}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def get_all_domains_with_yoe(given_role):\n",
        "  global db\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"DOMAINS\": {{string \"Domain name\":float \"years_used\"}} // A list of various industries/domain consolidate if possible (ex banking, Finance into BFSI) example: Healthcare,Retail and Finance along with years worked\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  #  \"HIGHEST_DESIGNATION\": string // highest designation he has worked as\n",
        "  #  \"IS_DOWNGRADE\": String // is Java developer role lower compared to Architect role\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "  )\n",
        "  chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "  query=\"\"\"\n",
        "        What are the various industries or software domain or verticals he has worked on along with years of experience for each\n",
        "        \"\"\"\n",
        "  #      What is his highest designation he has worked as\n",
        "  #      Is \"\"\"+Check_role+\"\"\" designation lower than Architect according to corporate designation ladder give reasons\n",
        "\n",
        "  result = qa.run(query)\n",
        "  #print(result)\n",
        "  #print(type(result))\n",
        "  if \"```json\" in result:\n",
        "    #print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    #print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  #pprint.pprint(structured_output)\n",
        "  return structured_output\n",
        "\n",
        "def job_stability():\n",
        "  global db\n",
        "\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"CURRENT_EMPLOYMENT\": string  // A company name indicating where is the candidate currently working\n",
        "    \"START_DATE\": date // Date in MMM-YYYY format showing when he started working with his current employment\n",
        "    \"STAY\": string // total years and months elapsed since START_DATE till \"\"\"+datetime.today().strftime('%B %Y')+\"\"\"\n",
        "    \"TOTAL_YEARS_EXPERIENCE\": int // total years of experience considering today as \"\"\"+datetime.today().strftime('%d %B %Y')+\"\"\"\n",
        "    \"TOTAL_COMPANIES_WORKED\": int // total number of companies he has worked\n",
        "    \"WAS_JOB_HOPPER\": string // yes or no whether he has showed tendency of job hopping in the past\n",
        "    \"JOB_HOPPER_CONSIDERATIONS\": string // Define why he is or is not a Job Hopper\n",
        "    \"CANDIDATE_NAME\": string // The name of the candidate\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "  )\n",
        "  chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "  query=\"\"\"where is he working currently\n",
        "        What is the start date of his current employment\n",
        "        What is the time elapsed since his start date Assuming today is \"\"\"+datetime.today().strftime('%d %B %Y')+\"\"\"\n",
        "        How much he has experience considering today is \"\"\"+datetime.today().strftime('%d %B %Y')+\"\"\"\n",
        "        How much companies has he worked in\n",
        "        Was he a job hopper in the past\n",
        "        Give reasons for job hopper considerations\n",
        "        what is the name of the candidate\n",
        "        \"\"\"\n",
        "\n",
        "  result = qa.run(query)\n",
        "  #print(result)\n",
        "  #print(type(result))\n",
        "  if \"```json\" in result:\n",
        "    #print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    #print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  #pprint.pprint(structured_output)\n",
        "  return structured_output"
      ],
      "metadata": {
        "id": "GHcT4LVGApjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = get_all_domains_with_yoe(\"java developer\")\n",
        "ans2 = job_stability()\n",
        "pprint.pprint(ans)\n",
        "pprint.pprint(ans2)"
      ],
      "metadata": {
        "id": "QbJXP-CtA9lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adef get_all_skills(given_role):\n",
        "  global db\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"PROGRAMMING_LANGUAGES\": list  // A list of all the programming languages example: Java, Python, C++, and JavaScript\n",
        "    \"SDEs/IDEs\": list // A list of all the software development environment(IDEs) example: Eclipse, Visual Studio, and IntelliJ IDEA\n",
        "    \"DOMAINS\": list // A list of various industries/domain consolidate if possible (ex banking, Finance into BFSI) example: Healthcare,Retail and Finance\n",
        "    \"DATABASES\": list // A list of various databases Check only for popular known databases example: MySQL, MongoDB and Neo4J\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  #  \"HIGHEST_DESIGNATION\": string // highest designation he has worked as\n",
        "  #  \"IS_DOWNGRADE\": String // is Java developer role lower compared to Architect role\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "  )\n",
        "  chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "  query=\"\"\"\n",
        "        With respect to the role of \"\"\"+given_role+\"\"\"\n",
        "        What are all the programming languages he/she is aware of\n",
        "        what are all the software development environment(IDEs) he/she has used\n",
        "        What are the various industries/domain he has worked on\n",
        "        What are the various well known databases he has worked on\n",
        "        \"\"\"\n",
        "  #      What is his highest designation he has worked as\n",
        "  #      Is \"\"\"+Check_role+\"\"\" designation lower than Architect according to corporate designation ladder give reasons\n",
        "\n",
        "  result = qa.run(query)\n",
        "  #print(result)\n",
        "  #print(type(result))\n",
        "  if \"```json\" in result:\n",
        "    print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  pprint.pprint(structured_output)\n",
        "  return structured_output\n",
        "\n",
        "def get_all_skills_with_yoe(given_role):\n",
        "  global db\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"PROGRAMMING_LANGUAGES\": {{string \"programming language\":float \"years_used\"}}  // A json of all the programming languages example: Java, Python, C++, and JavaScript with the years of usage\n",
        "    \"SDEs/IDEs\": {{string \"SDE name\":float \"years_used\"}} // A list of all the software development environment(IDEs) example: Eclipse, Visual Studio, and IntelliJ IDEA along with years used\n",
        "    \"DOMAINS\": {{string \"Domain name\":float \"years_used\"}} // A list of various industries/domain consolidate if possible (ex banking, Finance into BFSI) example: Healthcare,Retail and Finance along with years worked\n",
        "    \"DATABASES\": {{string \"database name\":float \"years_used\"}} // A list of various databases Check only for popular known databases example: MySQL, MongoDB and Neo4J along with years used\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  #  \"HIGHEST_DESIGNATION\": string // highest designation he has worked as\n",
        "  #  \"IS_DOWNGRADE\": String // is Java developer role lower compared to Architect role\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "  )\n",
        "  chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "  query=\"\"\"What are all the programming languages he/she is aware of with respect to \"\"\"+given_role+\"\"\" along with years of experience for each\n",
        "        what are all the software development environment(IDEs) he/she has used with respect to \"\"\"+given_role+\"\"\" along with years of experience for each\n",
        "        What are the various industries/domain he has worked on along with years of experience for each\n",
        "        What are the various well known databases he has worked on along with years of experience for each\n",
        "        \"\"\"\n",
        "  #      What is his highest designation he has worked as\n",
        "  #      Is \"\"\"+Check_role+\"\"\" designation lower than Architect according to corporate designation ladder give reasons\n",
        "\n",
        "  result = qa.run(query)\n",
        "  #print(result)\n",
        "  #print(type(result))\n",
        "  if \"```json\" in result:\n",
        "    print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  pprint.pprint(structured_output)\n",
        "  return structured_output\n",
        "\n",
        "def get_all_programming_lang_with_yoe(given_role):\n",
        "  global db\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"PROGRAMMING_LANGUAGES\": {{string \"programming language\":float \"years_used\"}}  // A json of all the programming languages example: Java, Python, C++, and JavaScript with the years of usage\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  #  \"HIGHEST_DESIGNATION\": string // highest designation he has worked as\n",
        "  #  \"IS_DOWNGRADE\": String // is Java developer role lower compared to Architect role\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "  )\n",
        "  chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "  query=\"\"\"What are all the programming languages he/she is aware of with respect to \"\"\"+given_role+\"\"\" along with years of experience for each\n",
        "        \"\"\"\n",
        "  #      What is his highest designation he has worked as\n",
        "  #      Is \"\"\"+Check_role+\"\"\" designation lower than Architect according to corporate designation ladder give reasons\n",
        "\n",
        "  result = qa.run(query)\n",
        "  #print(result)\n",
        "  #print(type(result))\n",
        "  if \"```json\" in result:\n",
        "    print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  pprint.pprint(structured_output)\n",
        "  return structured_output\n",
        "\n",
        "\n",
        "\n",
        "def get_all_databases_with_yoe(given_role):\n",
        "  global db\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"DATABASES\": {{string \"database name\":float \"years_used\"}} // A list of various databases Check only for popular known databases example: MySQL, MongoDB and Neo4J along with years used\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "  #  \"HIGHEST_DESIGNATION\": string // highest designation he has worked as\n",
        "  #  \"IS_DOWNGRADE\": String // is Java developer role lower compared to Architect role\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "  )\n",
        "  chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "  query=\"\"\"\n",
        "        What are the various well known databases he has worked on along with years of experience for each\n",
        "        \"\"\"\n",
        "  #      What is his highest designation he has worked as\n",
        "  #      Is \"\"\"+Check_role+\"\"\" designation lower than Architect according to corporate designation ladder give reasons\n",
        "\n",
        "  result = qa.run(query)\n",
        "  #print(result)\n",
        "  #print(type(result))\n",
        "  if \"```json\" in result:\n",
        "    print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    #print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  #pprint.pprint(structured_output)\n",
        "  return structured_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def star_check_pydantic(all_known_institutes):\n",
        "  class Institution(BaseModel):\n",
        "    name : str = Field(description=\"Name of the Institution\")\n",
        "    is_top_tier: str = Field(description=\"Yes or No\")\n",
        "    reason: str = Field(description=\"Reason why it is or is not top tier\")\n",
        "\n",
        "  class Stars(BaseModel):\n",
        "    STAR_INSTITUTION: Dict[str, Institution] = Field(description=\"dictionary of top tier company\")\n",
        "    STAR_EMPLOYERS: Dict[str, Institution] = Field(description=\"dictionary of top tier institution\")\n",
        "\n",
        "  parser = PydanticOutputParser(pydantic_object=Stars)\n",
        "\n",
        "  main_query = \"\"\"\n",
        "  Given a list of educational institution and organizations identify top tier educational institution and top tier organization\n",
        "  companies in the leagues of Meta, Apple, Netflix, Google, Microsoft or Testla can be considered as top tier\n",
        "  educational institute should be in the leagues of IIT, IIM and Cambridge can be considered as top tier\n",
        "  Include only top tier in the answer\n",
        "\n",
        "  \"LIST_OF_EDUCATION\": [\"Madras University, Chennai\"],\n",
        "  \"LIST_OF_EMPLOYERS\": [\"Alten Calsoftlabs\",\n",
        "                       \"Third ware\",\n",
        "                       \"Hewlett -Packard\",\n",
        "                       \"TCS\",\n",
        "                       \"Virtusa\",\n",
        "                       \"Satyam\"]\n",
        "\n",
        "  \"\"\"\n",
        "  prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        "  )\n",
        "\n",
        "  _input = prompt.format_prompt(query=main_query)\n",
        "  output = choice_of_llm(_input.to_string())\n",
        "  parser.parse(output)\n",
        "  return(parser.parse(output))\n",
        "\n",
        "def star_check(all_known_institutes):\n",
        "  template = \"\"\"\n",
        "  Given a list of educational institution LIST_OF_EDUCATION and organizations LIST_OF_EMPLOYERS\n",
        "  I want to identify top tier educational institution called STAR_INSTITUTIONS and top tier organization STAR_COMPANIES\n",
        "  I consider companies in the same level of brand recognition of Meta, Apple, Netflix, Google, Microsoft or Testla as top tier\n",
        "  I consider educational institute in the same level of brand recognition as IIT, IIM and Cambridge as top tier\n",
        "\n",
        "  Here is the given input:\n",
        "\n",
        "    \"LIST_OF_EDUCATION\": [\"Madras University, Chennai\"],\n",
        "    \"LIST_OF_EMPLOYERS\": [\"Alten Calsoftlabs\",\n",
        "                        \"Third ware\",\n",
        "                        \"Hewlett -Packard\",\n",
        "                        \"TCS\",\n",
        "                        \"Virtusa\",\n",
        "                        \"Satyam\"]\n",
        "\n",
        "    The output should be a markdown code snippet formatted as a JSON instance that conforms to the JSON schema below, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "    ```json\n",
        "    {{\n",
        "      \"STAR_INSTITUTION\": {{\"IIT Madras\":\"Top Institute within India and hence can be considered as a top tier University\"}}\n",
        "      \"STAR_EMPLOYERS\": {{\"Microsoft\":\"Microsoft is one of the top technology services company with a great brand reputation\"}}\n",
        "    }}\n",
        "  ```\n",
        "\n",
        "  In case none qualifies empty results:\n",
        "  ```json\n",
        "  {{\n",
        "  \"STAR_INSTITUTION\": None,\n",
        "  \"STAR_EMPLOYERS\": None\n",
        "  }}\n",
        "  ```\n",
        "  \"\"\"\n",
        "  prompt = PromptTemplate(template=template, input_variables=[\"institutions\"])\n",
        "\n",
        "  intelligent_llm_chain = LLMChain(prompt=prompt, llm=choice_of_llm)\n",
        "  result_2 = intelligent_llm_chain.run(all_known_institutes)\n",
        "  #print(result_2)\n",
        "  if \"```json\" in result_2:\n",
        "    print(\"formatting 2\")\n",
        "    json_string_2 = result_2.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    #print(json_string_2)\n",
        "    structured_output_2=json.loads(json_string_2)\n",
        "    return structured_output_2\n",
        "  else:\n",
        "    json_string_2 = result_2\n",
        "    return json_string_2\n",
        "\n",
        "def academic_professional_stardom():\n",
        "  global db\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"LIST_OF_EDUCATION\": list  // A list of educational institutions\n",
        "    \"LIST_OF_EMPLOYERS\": list // A list of companies\n",
        "  }}\n",
        "  ```\"\"\"\n",
        "\n",
        "  PROMPT = PromptTemplate(\n",
        "      template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        "  )\n",
        "  chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "  qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "  query=\"\"\"what are all the educational institution he has studied in\n",
        "          What are all the companies he has worked at\n",
        "        \"\"\"\n",
        "      #       Is any of these institution Top tier or premium institute\n",
        "\n",
        "      # Is there any top tier company he has worked at\n",
        "\n",
        "  #      What is his highest designation he has worked as\n",
        "  #      Is \"\"\"+Check_role+\"\"\" designation lower than Architect according to corporate designation ladder give reasons\n",
        "\n",
        "  result = qa.run(query)\n",
        "  #print(result)\n",
        "  #print(type(result))\n",
        "  if \"```json\" in result:\n",
        "    print(\"formatting\")\n",
        "    json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    #print(json_string)\n",
        "    structured_output=json.loads(json_string)\n",
        "    structured_output_2 = star_check(json_string)\n",
        "  else:\n",
        "    json_string = result\n",
        "\n",
        "  pprint.pprint(structured_output)\n",
        "  pprint.pprint(structured_output_2)\n",
        "  cons_output = structured_output | structured_output_2\n",
        "  return cons_output\n"
      ],
      "metadata": {
        "id": "QkNOB5pMkueg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skills_organizer(\"Java developer\",\"Software\")"
      ],
      "metadata": {
        "id": "ew3Jz4vh3Ec0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_all_skills_experience(\"Java developer\",All_software_skills[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVhSFNDxVmiX",
        "outputId": "44afed34-b859-4bb9-fff0-c26bc21096fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        For all the software terms given find the years of experience for each if not available give NA\n",
            "        [Spring,\n",
            "PCF,\n",
            "EJB,\n",
            "JPA,\n",
            "FindBugs]\n",
            "\n",
            "        \n",
            "formatting\n",
            "{\n",
            "  \"Spring\": \"Nov 2007 to June 2008, October 2006 to October 2007, July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017\",\n",
            "  \"PCF\": \"NA\",\n",
            "  \"EJB\": \"July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017\",\n",
            "  \"JPA\": \"July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017\",\n",
            "  \"FindBugs\": \"July 2012 to Nov 2013\"\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_all_skills_experience(\"Java developer\",All_software_skills[20:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNTCtjnzVsNB",
        "outputId": "a51a56df-78bb-4865-d30f-90227ae7275e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        For all the software terms given find the years of experience for each if not available give NA\n",
            "        [Spring Boot,\n",
            "Ajax,\n",
            "Anypoint studio 7.6,\n",
            "AngularJS,\n",
            "SOAP Web services,\n",
            "WCS 11.1.8,\n",
            "Peoplesoft,\n",
            "Oracle,\n",
            "Hibernate,\n",
            "JSF 2.0]\n",
            "\n",
            "        \n",
            "formatting\n",
            "{\n",
            "  \"Spring Boot\" : \"NA\",\n",
            "  \"Ajax\" : \"NA\",\n",
            "  \"Anypoint studio 7.6\" : \"NA\",\n",
            "  \"AngularJS\" : \"Oct 2006 to Oct 2007\",\n",
            "  \"SOAP Web services\" : \"Nov 2007 to June 2008, Dec 2015 to July 2017\",\n",
            "  \"WCS 11.1.8\" : \"Oct 2006 to Oct 2007\",\n",
            "  \"Peoplesoft\" : \"NA\",\n",
            "  \"Oracle\" : \"Nov 2007 to June 2008, July 2012 to Nov 2013, Dec 2015 to July 2017\",\n",
            "  \"Hibernate\" : \"Nov 2007 to June 2008, July 2012 to Nov 2013\",\n",
            "  \"JSF 2.0\" : \"Nov 2007 to June 2008\"\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "def fn1(num):\n",
        "  return num+1\n",
        "def fn2(num):\n",
        "  return num+2\n",
        "def fn3(num):\n",
        "  return num+10\n",
        "def fn4(num):\n",
        "  return num+100\n",
        "\n",
        "p = Pool(processes=4)\n",
        "data = p.map(fn1, 1)\n",
        "data = p.map(fn2, 1)\n",
        "data = p.map(fn3, 1)\n",
        "data = p.map(fn4, 1)\n",
        "p.close()\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "TlqyjDdPyhvm",
        "outputId": "4ea6d2d8-61ef-4d74-eb08-a0df29a12222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a583b840e503>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         '''\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_map_async\u001b[0;34m(self, func, iterable, mapper, chunksize, callback, error_callback)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "def fn1(num):\n",
        "  return num+1\n",
        "def fn2(num):\n",
        "  return num+2\n",
        "def fn3(num):\n",
        "  return num+10\n",
        "def fn4(num):\n",
        "  return num+100\n",
        "\n",
        "p = multiprocessing.Process(target=fn1, args=(2,))\n",
        "p.start()\n",
        "q = multiprocessing.Process(target=fn2, args=(2,))\n",
        "q.start()\n",
        "r = multiprocessing.Process(target=fn3, args=(2,))\n",
        "r.start()\n",
        "s = multiprocessing.Process(target=fn4, args=(2,))\n",
        "s.start()\n",
        "\n",
        "print(p,q,r,s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmjBZExvt3jN",
        "outputId": "245ab1db-e129-4b31-f8b9-9fefb061e350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Process name='Process-17' pid=11999 parent=163 stopped exitcode=0> <Process name='Process-18' pid=12000 parent=163 stopped exitcode=0> <Process name='Process-19' pid=12001 parent=163 stopped exitcode=0> <Process name='Process-20' pid=12002 parent=163 started>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def total_months(daterange):\n",
        "# assigning months to numbers\n",
        "  months = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6, 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12,\n",
        "            'january':1, 'february':2, 'march':3, 'april':4, 'may':5, 'june':6, 'july':7, 'august':8, 'september':9, 'october':10, 'november':11, 'december':12,\n",
        "            'sept':9}\n",
        "\n",
        "# getting the two dates\n",
        "  start_date = daterange.split(' to ')[0].strip().lower()\n",
        "  end_date = daterange.split(' to ')[1].strip().lower()\n",
        "\n",
        "# convert the dates to number and subtract them\n",
        "  start_month = months[start_date.split(' ')[0].lower()]\n",
        "  start_year = int(start_date.split(' ')[1])\n",
        "  end_month = months[end_date.split(' ')[0].lower()]\n",
        "  end_year = int(end_date.split(' ')[1])\n",
        "\n",
        "  diff_years = end_year - start_year\n",
        "  diff_month = end_month - start_month\n",
        "  total_months = (diff_years*12)+diff_month\n",
        "  return total_months\n",
        "\n",
        "def format_year_month(x):\n",
        "    y = x // 12\n",
        "    m = x % 12\n",
        "    return str(y)+ 'y-' + str(m) + 'm'\n",
        "\n",
        "fin = {\n",
        "  \"Spring\": \"Nov 2007 to June 2008, October 2006 to October 2007, July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017\",\n",
        "  \"PCF\": \"NA\",\n",
        "  \"EJB\": \"July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017\",\n",
        "  \"JPA\": \"July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017\",\n",
        "  \"FindBugs\": \"July 2012 to Nov 2013\"\n",
        "}\n",
        "\n",
        "temp_fin = {}\n",
        "\n",
        "for key in fin.keys():\n",
        "  if fin[key] != \"NA\":\n",
        "    ##temp_fin[key] = []\n",
        "    temp = fin[key].split(\",\")\n",
        "    total = 0\n",
        "    for dat_range in temp:\n",
        "      #print(dat_range,\" : \",total_months(dat_range))\n",
        "      total = total + total_months(dat_range)\n",
        "    ##temp_fin[key].append(total_months(dat_range))\n",
        "    temp_fin[key] = format_year_month(total)\n",
        "print(fin)\n",
        "print(temp_fin)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQNyvrWLlb7A",
        "outputId": "0aedcb9c-1136-4a5c-c52e-da825fa7f7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Spring': 'Nov 2007 to June 2008, October 2006 to October 2007, July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017', 'PCF': 'NA', 'EJB': 'July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017', 'JPA': 'July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017', 'FindBugs': 'July 2012 to Nov 2013'}\n",
            "{'Spring': '4y-10m', 'EJB': '3y-3m', 'JPA': '3y-3m', 'FindBugs': '1y-4m'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skill_with_years = {}\n",
        "for i in range(0,math.ceil(len(All_software_skills)/5)):\n",
        "  if i+(5*i) != len(All_software_skills):\n",
        "    #print(i*10,10*(i+1))\n",
        "    #print(All_software_skills[i*10:10*(i+1)])\n",
        "    result = get_all_skills_experience(\"Java developer\",All_software_skills[i*5:5*(i+1)])\n",
        "  else:\n",
        "    #print(i*10,i+(10*i))\n",
        "    #print(All_software_skills[i*10:i+(10*i)])\n",
        "    result = get_all_skills_experience(\"Java developer\",All_software_skills[i*5:i+(5*i)])\n",
        "  for k in result.keys():\n",
        "    skill_with_years[k] = result[k]\n",
        "#result = get_all_skills_experience(\"Java developer\")\n",
        "pprint.pprint(skill_with_years)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXjT3Q1KFn0a",
        "outputId": "3a5b4112-c32e-424f-fa1e-fe436100bc04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        For all the software terms given find the years of experience for each if not available give NA\n",
            "        [Spring,\n",
            "PCF,\n",
            "EJB,\n",
            "JPA,\n",
            "FindBugs]\n",
            "\n",
            "        \n",
            "formatting\n",
            "{\n",
            "  \"Spring\": \"Nov 2007 to June 2008, October 2006 to October 2007, July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017\",\n",
            "  \"PCF\": \"NA\",\n",
            "  \"EJB\": \"July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017\",\n",
            "  \"JPA\": \"July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017\",\n",
            "  \"FindBugs\": \"July 2012 to Nov 2013\"\n",
            "}\n",
            "\n",
            "\n",
            "        For all the software terms given find the years of experience for each if not available give NA\n",
            "        [SOAP/REST Web service,\n",
            "Mule 3x/4x runtime,\n",
            "Struts,\n",
            "Jsf,\n",
            "Cloudhub]\n",
            "\n",
            "        \n",
            "formatting\n",
            "{\n",
            "  \"SOAP/REST Web service\": \"Mar 2011 to July 2011\",\n",
            "  \"Mule 3x/4x runtime\": \"Oct 2006 to Oct 2007\",\n",
            "  \"Struts\": \"Nov 2007 to June 2008\",\n",
            "  \"Jsf\": \"Nov 2007 to June 2008\",\n",
            "  \"Cloudhub\": \"Mar 2011 to July 2011\"\n",
            "}\n",
            "\n",
            "\n",
            "        For all the software terms given find the years of experience for each if not available give NA\n",
            "        [REST/JSON Web services,\n",
            "Jenkins,\n",
            "iBatis,\n",
            "Mule 3x/4x,\n",
            "Go Pipelines]\n",
            "\n",
            "        \n",
            "formatting\n",
            "{\n",
            "  \"REST/JSON Web services\" : \"Dec 2015 to July 2017\",\n",
            "  \"Jenkins\" : \"August 2017 to December 2017\",\n",
            "  \"iBatis\" : \"July 2012 to Nov 2013\",\n",
            "  \"Mule 3x/4x\" : \"January 2018 to September 2018\",\n",
            "  \"Go Pipelines\" : \"NA\"\n",
            "}\n",
            "\n",
            "\n",
            "        For all the software terms given find the years of experience for each if not available give NA\n",
            "        [Sonargraph,\n",
            "ibatis,\n",
            "Github,\n",
            "Gradle,\n",
            "DB2]\n",
            "\n",
            "        \n",
            "formatting\n",
            "{\n",
            "  \"Sonargraph\": \"NA\",\n",
            "  \"ibatis\": \"Nov 2007 to June 2008\",\n",
            "  \"Github\": \"NA\",\n",
            "  \"Gradle\": \"NA\",\n",
            "  \"DB2\": \"NA\"\n",
            "}\n",
            "\n",
            "\n",
            "        For all the software terms given find the years of experience for each if not available give NA\n",
            "        [Spring Boot,\n",
            "Ajax,\n",
            "Anypoint studio 7.6,\n",
            "AngularJS,\n",
            "SOAP Web services]\n",
            "\n",
            "        \n",
            "formatting\n",
            "{\n",
            "  \"Spring Boot\" : \"NA\",\n",
            "  \"Ajax\" : \"Nov 2007 to June 2008\",\n",
            "  \"Anypoint studio 7.6\" : \"NA\",\n",
            "  \"AngularJS\" : \"October 2006 to October 2007\",\n",
            "  \"SOAP Web services\" : \"July 2012 to Nov 2013\"\n",
            "}\n",
            "\n",
            "\n",
            "        For all the software terms given find the years of experience for each if not available give NA\n",
            "        [WCS 11.1.8,\n",
            "Peoplesoft,\n",
            "Oracle,\n",
            "Hibernate,\n",
            "JSF 2.0]\n",
            "\n",
            "        \n",
            "formatting\n",
            "{\n",
            "\"WCS 11.1.8\" : \"Mar 2011 to July 2011\",\n",
            "\"Peoplesoft\" : \"NA\",\n",
            "\"Oracle\" : \"Oct 2006 to Oct 2007, Mar 2011 to Nov 2013\",\n",
            "\"Hibernate\" : \"July 2012 to Nov 2013\",\n",
            "\"JSF 2.0\" : \"Oct 2006 to Oct 2007\"\n",
            "}\n",
            "\n",
            "\n",
            "        For all the software terms given find the years of experience for each if not available give NA\n",
            "        [Ford framework for Java,\n",
            "SonarQube,\n",
            "DB2 Stored Procedures]\n",
            "\n",
            "        \n",
            "formatting\n",
            "{\n",
            "    \"Ford framework for Java\" : \"Nov 2007 to June 2008\",\n",
            "    \"SonarQube\" : \"NA\",\n",
            "    \"DB2 Stored Procedures\" : \"July 2012 to Nov 2013\"\n",
            "}\n",
            "\n",
            "{'Ajax': 'Nov 2007 to June 2008',\n",
            " 'AngularJS': 'October 2006 to October 2007',\n",
            " 'Anypoint studio 7.6': 'NA',\n",
            " 'Cloudhub': 'Mar 2011 to July 2011',\n",
            " 'DB2': 'NA',\n",
            " 'DB2 Stored Procedures': 'July 2012 to Nov 2013',\n",
            " 'EJB': 'July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July '\n",
            "        '2017',\n",
            " 'FindBugs': 'July 2012 to Nov 2013',\n",
            " 'Ford framework for Java': 'Nov 2007 to June 2008',\n",
            " 'Github': 'NA',\n",
            " 'Go Pipelines': 'NA',\n",
            " 'Gradle': 'NA',\n",
            " 'Hibernate': 'July 2012 to Nov 2013',\n",
            " 'JPA': 'July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July '\n",
            "        '2017',\n",
            " 'JSF 2.0': 'Oct 2006 to Oct 2007',\n",
            " 'Jenkins': 'August 2017 to December 2017',\n",
            " 'Jsf': 'Nov 2007 to June 2008',\n",
            " 'Mule 3x/4x': 'January 2018 to September 2018',\n",
            " 'Mule 3x/4x runtime': 'Oct 2006 to Oct 2007',\n",
            " 'Oracle': 'Oct 2006 to Oct 2007, Mar 2011 to Nov 2013',\n",
            " 'PCF': 'NA',\n",
            " 'Peoplesoft': 'NA',\n",
            " 'REST/JSON Web services': 'Dec 2015 to July 2017',\n",
            " 'SOAP Web services': 'July 2012 to Nov 2013',\n",
            " 'SOAP/REST Web service': 'Mar 2011 to July 2011',\n",
            " 'SonarQube': 'NA',\n",
            " 'Sonargraph': 'NA',\n",
            " 'Spring': 'Nov 2007 to June 2008, October 2006 to October 2007, July 2012 to '\n",
            "           'Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017',\n",
            " 'Spring Boot': 'NA',\n",
            " 'Struts': 'Nov 2007 to June 2008',\n",
            " 'WCS 11.1.8': 'Mar 2011 to July 2011',\n",
            " 'iBatis': 'July 2012 to Nov 2013',\n",
            " 'ibatis': 'Nov 2007 to June 2008'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "SAMPLE_SKILL_YOE = {'Ajax': 'Nov 2007 to June 2008',\n",
        " 'AngularJS': 'October 2006 to October 2007',\n",
        " 'Anypoint studio 7.6': 'NA',\n",
        " 'Cloudhub': 'Mar 2011 to July 2011',\n",
        " 'DB2': 'NA',\n",
        " 'DB2 Stored Procedures': 'July 2012 to Nov 2013',\n",
        " 'EJB': 'July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July '\n",
        "        '2017',\n",
        " 'FindBugs': 'July 2012 to Nov 2013',\n",
        " 'Ford framework for Java': 'Nov 2007 to June 2008',\n",
        " 'Github': 'NA',\n",
        " 'Go Pipelines': 'NA',\n",
        " 'Gradle': 'NA',\n",
        " 'Hibernate': 'July 2012 to Nov 2013',\n",
        " 'JPA': 'July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July '\n",
        "        '2017',\n",
        " 'JSF 2.0': 'Oct 2006 to Oct 2007',\n",
        " 'Jenkins': 'August 2017 to December 2017',\n",
        " 'Jsf': 'Nov 2007 to June 2008',\n",
        " 'Mule 3x/4x': 'January 2018 to September 2018',\n",
        " 'Mule 3x/4x runtime': 'Oct 2006 to Oct 2007',\n",
        " 'Oracle': 'Oct 2006 to Oct 2007, Mar 2011 to Nov 2013',\n",
        " 'PCF': 'NA',\n",
        " 'Peoplesoft': 'NA',\n",
        " 'REST/JSON Web services': 'Dec 2015 to July 2017',\n",
        " 'SOAP Web services': 'July 2012 to Nov 2013',\n",
        " 'SOAP/REST Web service': 'Mar 2011 to July 2011',\n",
        " 'SonarQube': 'NA',\n",
        " 'Sonargraph': 'NA',\n",
        " 'Spring': 'Nov 2007 to June 2008, October 2006 to October 2007, July 2012 to '\n",
        "           'Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017',\n",
        " 'Spring Boot': 'NA',\n",
        " 'Struts': 'Nov 2007 to June 2008',\n",
        " 'WCS 11.1.8': 'Mar 2011 to July 2011',\n",
        " 'iBatis': 'July 2012 to Nov 2013',\n",
        " 'ibatis': 'Nov 2007 to June 2008'}\n",
        "\n",
        "SAMPLE_SKILL_CATEGORIES = {\n",
        "    'Software APIs': ['SOAP/REST Web service',\n",
        "                   'REST/JSON Web services',\n",
        "                   'SOAP Web services'],\n",
        "    'Software Databases': ['DB2', 'Oracle'],\n",
        "    'Software Development Frameworks': ['Spring',\n",
        "                                     'Struts',\n",
        "                                     'JSF 2.0',\n",
        "                                     'Ford framework for Java',\n",
        "                                     'AngularJS'],\n",
        "    'Software Development Tools': ['FindBugs',\n",
        "                                'Jenkins',\n",
        "                                'iBatis',\n",
        "                                'Go Pipelines',\n",
        "                                'Sonargraph',\n",
        "                                'SonarQube',\n",
        "                                'Gradle'],\n",
        "    'Software ORM': ['EJB', 'JPA', 'Hibernate'],\n",
        "    'Software Platforms': ['PCF',\n",
        "                        'Mule 3x/4x runtime',\n",
        "                        'Cloudhub',\n",
        "                        'Anypoint studio 7.6',\n",
        "                        'WCS 11.1.8',\n",
        "                        'Peoplesoft'],\n",
        "    'Software Programming Languages': ['Java', 'Ajax'],\n",
        "    'Software Stored Procedures': ['DB2 Stored Procedures'],\n",
        "    'Software Version Control': ['Github']}\n",
        "\n",
        "temp_fin = {}\n",
        "\n",
        "for key in SAMPLE_SKILL_YOE.keys():\n",
        "  if SAMPLE_SKILL_YOE[key] != \"NA\":\n",
        "    ##temp_fin[key] = []\n",
        "    temp = SAMPLE_SKILL_YOE[key].split(\",\")\n",
        "    total = 0\n",
        "    for dat_range in temp:\n",
        "      #print(dat_range,\" : \",total_months(dat_range))\n",
        "      total = total + total_months(dat_range)\n",
        "    ##temp_fin[key].append(total_months(dat_range))\n",
        "    temp_fin[key] = format_year_month(total)\n",
        "print(SAMPLE_SKILL_YOE)\n",
        "print(temp_fin)\n",
        "\n",
        "exp_cat = {}\n",
        "for cat in SAMPLE_SKILL_CATEGORIES.keys():\n",
        "  exp_cat[cat] = {}\n",
        "  for vals in SAMPLE_SKILL_CATEGORIES[cat]:\n",
        "    try:\n",
        "      exp_cat[cat][vals] = temp_fin[vals]\n",
        "    except KeyError:\n",
        "      exp_cat[cat][vals] = \"NA\"\n",
        "\n",
        "pprint.pprint(exp_cat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OInco7EX4u2O",
        "outputId": "3a0edd88-a0cc-4d67-def4-83fc038493bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Ajax': 'Nov 2007 to June 2008', 'AngularJS': 'October 2006 to October 2007', 'Anypoint studio 7.6': 'NA', 'Cloudhub': 'Mar 2011 to July 2011', 'DB2': 'NA', 'DB2 Stored Procedures': 'July 2012 to Nov 2013', 'EJB': 'July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017', 'FindBugs': 'July 2012 to Nov 2013', 'Ford framework for Java': 'Nov 2007 to June 2008', 'Github': 'NA', 'Go Pipelines': 'NA', 'Gradle': 'NA', 'Hibernate': 'July 2012 to Nov 2013', 'JPA': 'July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017', 'JSF 2.0': 'Oct 2006 to Oct 2007', 'Jenkins': 'August 2017 to December 2017', 'Jsf': 'Nov 2007 to June 2008', 'Mule 3x/4x': 'January 2018 to September 2018', 'Mule 3x/4x runtime': 'Oct 2006 to Oct 2007', 'Oracle': 'Oct 2006 to Oct 2007, Mar 2011 to Nov 2013', 'PCF': 'NA', 'Peoplesoft': 'NA', 'REST/JSON Web services': 'Dec 2015 to July 2017', 'SOAP Web services': 'July 2012 to Nov 2013', 'SOAP/REST Web service': 'Mar 2011 to July 2011', 'SonarQube': 'NA', 'Sonargraph': 'NA', 'Spring': 'Nov 2007 to June 2008, October 2006 to October 2007, July 2012 to Nov 2013, August 2017 to December 2017, Dec 2015 to July 2017', 'Spring Boot': 'NA', 'Struts': 'Nov 2007 to June 2008', 'WCS 11.1.8': 'Mar 2011 to July 2011', 'iBatis': 'July 2012 to Nov 2013', 'ibatis': 'Nov 2007 to June 2008'}\n",
            "{'Ajax': '0y-7m', 'AngularJS': '1y-0m', 'Cloudhub': '0y-4m', 'DB2 Stored Procedures': '1y-4m', 'EJB': '3y-3m', 'FindBugs': '1y-4m', 'Ford framework for Java': '0y-7m', 'Hibernate': '1y-4m', 'JPA': '3y-3m', 'JSF 2.0': '1y-0m', 'Jenkins': '0y-4m', 'Jsf': '0y-7m', 'Mule 3x/4x': '0y-8m', 'Mule 3x/4x runtime': '1y-0m', 'Oracle': '3y-8m', 'REST/JSON Web services': '1y-7m', 'SOAP Web services': '1y-4m', 'SOAP/REST Web service': '0y-4m', 'Spring': '4y-10m', 'Struts': '0y-7m', 'WCS 11.1.8': '0y-4m', 'iBatis': '1y-4m', 'ibatis': '0y-7m'}\n",
            "{'Software APIs': {'REST/JSON Web services': '1y-7m',\n",
            "                   'SOAP Web services': '1y-4m',\n",
            "                   'SOAP/REST Web service': '0y-4m'},\n",
            " 'Software Databases': {'DB2': 'NA', 'Oracle': '3y-8m'},\n",
            " 'Software Development Frameworks': {'AngularJS': '1y-0m',\n",
            "                                     'Ford framework for Java': '0y-7m',\n",
            "                                     'JSF 2.0': '1y-0m',\n",
            "                                     'Spring': '4y-10m',\n",
            "                                     'Struts': '0y-7m'},\n",
            " 'Software Development Tools': {'FindBugs': '1y-4m',\n",
            "                                'Go Pipelines': 'NA',\n",
            "                                'Gradle': 'NA',\n",
            "                                'Jenkins': '0y-4m',\n",
            "                                'SonarQube': 'NA',\n",
            "                                'Sonargraph': 'NA',\n",
            "                                'iBatis': '1y-4m'},\n",
            " 'Software ORM': {'EJB': '3y-3m', 'Hibernate': '1y-4m', 'JPA': '3y-3m'},\n",
            " 'Software Platforms': {'Anypoint studio 7.6': 'NA',\n",
            "                        'Cloudhub': '0y-4m',\n",
            "                        'Mule 3x/4x runtime': '1y-0m',\n",
            "                        'PCF': 'NA',\n",
            "                        'Peoplesoft': 'NA',\n",
            "                        'WCS 11.1.8': '0y-4m'},\n",
            " 'Software Programming Languages': {'Ajax': '0y-7m', 'Java': 'NA'},\n",
            " 'Software Stored Procedures': {'DB2 Stored Procedures': '1y-4m'},\n",
            " 'Software Version Control': {'Github': 'NA'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = get_skill_categorization(All_software_skills,\"Software\")\n",
        "pprint.pprint(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-UEZn_bTHT9",
        "outputId": "c0fa02e3-8e53-434a-9b8f-8f8b85c2285a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "{'Software APIs': ['SOAP/REST Web service',\n",
            "                   'REST/JSON Web services',\n",
            "                   'SOAP Web services'],\n",
            " 'Software Databases': ['DB2', 'Oracle'],\n",
            " 'Software Development Frameworks': ['Spring',\n",
            "                                     'Struts',\n",
            "                                     'JSF 2.0',\n",
            "                                     'Ford framework for Java',\n",
            "                                     'AngularJS'],\n",
            " 'Software Development Tools': ['FindBugs',\n",
            "                                'Jenkins',\n",
            "                                'iBatis',\n",
            "                                'Go Pipelines',\n",
            "                                'Sonargraph',\n",
            "                                'SonarQube',\n",
            "                                'Gradle'],\n",
            " 'Software ORM': ['EJB', 'JPA', 'Hibernate'],\n",
            " 'Software Platforms': ['PCF',\n",
            "                        'Mule 3x/4x runtime',\n",
            "                        'Cloudhub',\n",
            "                        'Anypoint studio 7.6',\n",
            "                        'WCS 11.1.8',\n",
            "                        'Peoplesoft'],\n",
            " 'Software Programming Languages': ['Java', 'Ajax'],\n",
            " 'Software Stored Procedures': ['DB2 Stored Procedures'],\n",
            " 'Software Version Control': ['Github']}\n",
            "{'Software APIs': ['SOAP/REST Web service',\n",
            "                   'REST/JSON Web services',\n",
            "                   'SOAP Web services'],\n",
            " 'Software Databases': ['DB2', 'Oracle'],\n",
            " 'Software Development Frameworks': ['Spring',\n",
            "                                     'Struts',\n",
            "                                     'JSF 2.0',\n",
            "                                     'Ford framework for Java',\n",
            "                                     'AngularJS'],\n",
            " 'Software Development Tools': ['FindBugs',\n",
            "                                'Jenkins',\n",
            "                                'iBatis',\n",
            "                                'Go Pipelines',\n",
            "                                'Sonargraph',\n",
            "                                'SonarQube',\n",
            "                                'Gradle'],\n",
            " 'Software ORM': ['EJB', 'JPA', 'Hibernate'],\n",
            " 'Software Platforms': ['PCF',\n",
            "                        'Mule 3x/4x runtime',\n",
            "                        'Cloudhub',\n",
            "                        'Anypoint studio 7.6',\n",
            "                        'WCS 11.1.8',\n",
            "                        'Peoplesoft'],\n",
            " 'Software Programming Languages': ['Java', 'Ajax'],\n",
            " 'Software Stored Procedures': ['DB2 Stored Procedures'],\n",
            " 'Software Version Control': ['Github']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = get_top_level_details_from_GPT(\"Java developer\",All_software_skills)\n",
        "pprint.pprint(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_O2WuWrf-Te",
        "outputId": "4ffaeac8-4fa7-497e-a835-a4ae5f46b4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "{\n",
            "    \"SCORE_FOR_JAVA_DEVELOPER\": \"90\",\n",
            "    \"OTHER_SUITABLE_ROLES\": [\"Software Engineer\", \"Full Stack Developer\", \"Backend Developer\", \"Frontend Developer\", \"DevOps Engineer\"],\n",
            "    \"TOP_SUITABLE_ROLES\": {\"Software Engineer\": \"95\"}\n",
            "  }\n",
            "  \n",
            "{'OTHER_SUITABLE_ROLES': ['Software Engineer',\n",
            "                          'Full Stack Developer',\n",
            "                          'Backend Developer',\n",
            "                          'Frontend Developer',\n",
            "                          'DevOps Engineer'],\n",
            " 'SCORE_FOR_JAVA_DEVELOPER': '90',\n",
            " 'TOP_SUITABLE_ROLES': {'Software Engineer': '95'}}\n",
            "{'OTHER_SUITABLE_ROLES': ['Software Engineer',\n",
            "                          'Full Stack Developer',\n",
            "                          'Backend Developer',\n",
            "                          'Frontend Developer',\n",
            "                          'DevOps Engineer'],\n",
            " 'SCORE_FOR_JAVA_DEVELOPER': '90',\n",
            " 'TOP_SUITABLE_ROLES': {'Software Engineer': '95'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_all_databases_with_yoe(\"Java developer\")\n",
        "pprint.pprint(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E_hWq0r44JM",
        "outputId": "4d39bf69-c45d-4f73-c553-7ecb284d452b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "{'DATABASES': {'MySQL': 0, 'Oracle 10g': 8.5, 'Oracle 11i': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_all_domains_with_yoe(\"Java developer\")\n",
        "pprint.pprint(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMwOWxh136Bu",
        "outputId": "bb0ea49c-0fb6-46cd-c61e-24a489070c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "{'DOMAINS': {'Automobile': 4.5,\n",
            "             'Banking and Finance': 1.5,\n",
            "             'Finance': 2.5,\n",
            "             'Telecom': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_all_programming_lang_with_yoe(\"Java developer\")\n",
        "pprint.pprint(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgzUTpPG2i3v",
        "outputId": "570a29d1-131b-43f1-fa14-8270f3f1a6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "{\n",
            "  \"PROGRAMMING_LANGUAGES\": {\n",
            "    \"Java\": 11.0,\n",
            "    \"Struts\": 11.0,\n",
            "    \"Ajax\": 11.0,\n",
            "    \"iBatis\": 11.0,\n",
            "    \"JPA\": 5.0,\n",
            "    \"SOAP Web services\": 11.0,\n",
            "    \"Spring\": 11.0,\n",
            "    \"AngularJS\": 3.0,\n",
            "    \"REST/JSON Web services\": 3.0,\n",
            "    \"WCS 11.1.8\": 1.0,\n",
            "    \"WebLogic 10\": 1.0,\n",
            "    \"Hibernate\": 2.0,\n",
            "    \"Ford framework for Java\": 2.0,\n",
            "    \"EJB\": 2.0,\n",
            "    \"PL/SQL\": 2.0,\n",
            "    \"UNIX shell scripting\": 2.0\n",
            "  }\n",
            "}\n",
            "\n",
            "{'PROGRAMMING_LANGUAGES': {'Ajax': 11.0,\n",
            "                           'AngularJS': 3.0,\n",
            "                           'EJB': 2.0,\n",
            "                           'Ford framework for Java': 2.0,\n",
            "                           'Hibernate': 2.0,\n",
            "                           'JPA': 5.0,\n",
            "                           'Java': 11.0,\n",
            "                           'PL/SQL': 2.0,\n",
            "                           'REST/JSON Web services': 3.0,\n",
            "                           'SOAP Web services': 11.0,\n",
            "                           'Spring': 11.0,\n",
            "                           'Struts': 11.0,\n",
            "                           'UNIX shell scripting': 2.0,\n",
            "                           'WCS 11.1.8': 1.0,\n",
            "                           'WebLogic 10': 1.0,\n",
            "                           'iBatis': 11.0}}\n",
            "{'PROGRAMMING_LANGUAGES': {'Ajax': 11.0,\n",
            "                           'AngularJS': 3.0,\n",
            "                           'EJB': 2.0,\n",
            "                           'Ford framework for Java': 2.0,\n",
            "                           'Hibernate': 2.0,\n",
            "                           'JPA': 5.0,\n",
            "                           'Java': 11.0,\n",
            "                           'PL/SQL': 2.0,\n",
            "                           'REST/JSON Web services': 3.0,\n",
            "                           'SOAP Web services': 11.0,\n",
            "                           'Spring': 11.0,\n",
            "                           'Struts': 11.0,\n",
            "                           'UNIX shell scripting': 2.0,\n",
            "                           'WCS 11.1.8': 1.0,\n",
            "                           'WebLogic 10': 1.0,\n",
            "                           'iBatis': 11.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "downgrade_check = is_downgrade(chosen_llm=choice_of_llm, given_role=\"Java developer\", top_role=\"Technical Architect\")\n",
        "pprint.pprint(downgrade_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afqwQRfC-e2E",
        "outputId": "fb29baa6-7085-48f9-b992-d95be3bcce3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting downgrade\n",
            "{'IS_DOWNGRADE': 'Yes',\n",
            " 'JAVA_DEVELOPER': 8,\n",
            " 'REASONS': 'A Technical Architect typically has more experience and a higher '\n",
            "            'level of responsibility than a Java Developer.',\n",
            " 'TECHNICAL_ARCHITECT': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stability_check = job_stability()\n",
        "pprint.pprint(stability_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKnqTD9gDTfm",
        "outputId": "3557dfaa-55cb-495b-e280-f86c9d20ab59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "{'CANDIDATE_NAME': 'Thyagarajan Gnanasekaran',\n",
            " 'CURRENT_EMPLOYMENT': 'Alten Calsoftlabs',\n",
            " 'JOB_HOPPER_CONSIDERATIONS': 'The candidate has worked with the same employer '\n",
            "                              'for 4 years and 8 months, which is a long '\n",
            "                              'period of time.',\n",
            " 'START_DATE': 'Nov-2018',\n",
            " 'STAY': '4 years and 8 months',\n",
            " 'WAS_JOB_HOPPER': 'No'}\n",
            "{'CANDIDATE_NAME': 'Thyagarajan Gnanasekaran',\n",
            " 'CURRENT_EMPLOYMENT': 'Alten Calsoftlabs',\n",
            " 'JOB_HOPPER_CONSIDERATIONS': 'The candidate has worked with the same employer '\n",
            "                              'for 4 years and 8 months, which is a long '\n",
            "                              'period of time.',\n",
            " 'START_DATE': 'Nov-2018',\n",
            " 'STAY': '4 years and 8 months',\n",
            " 'WAS_JOB_HOPPER': 'No'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some = star_check_pydantic(\"ll\")\n",
        "print(type(some))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "Bou5-yKsOWFw",
        "outputId": "2b506d92-4039-43e0-b801-8be89f7daabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutputParserException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/output_parsers/pydantic.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mjson_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mjson_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydantic_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 19 column 6 (char 585)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-8fa3b7090b24>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstar_check_pydantic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ll\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-62cea6aaed12>\u001b[0m in \u001b[0;36mstar_check_pydantic\u001b[0;34m(all_known_institutes)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0m_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoice_of_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m   \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/output_parsers/pydantic.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydantic_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Failed to parse {name} from completion {text}. Got: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOutputParserException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_format_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse Stars from completion   {\n  \"STAR_INSTITUTION\": {\n    \"Madras University, Chennai\": {\n      \"name\": \"Madras University, Chennai\",\n      \"is_top_tier\": \"No\",\n      \"reason\": \"Not in the leagues of IIT, IIM and Cambridge\"\n    }\n  },\n  \"STAR_EMPLOYERS\": {\n    \"Alten Calsoftlabs\": {\n      \"name\": \"Alten Calsoftlabs\",\n      \"is_top_tier\": \"No\",\n      \"reason\": \"Not in the leagues of Meta, Apple, Netflix, Google, Microsoft or Testla\"\n    },\n    \"Third ware\": {\n      \"name\": \"Third ware\",\n      \"is_top_tier\": \"No\",\n      \"reason\": \"Not in the leagues of Meta, Apple, Netflix, Google, Microsoft or Testla\"\n    },\n    \"Hewlett -Packard\": {\n      \"name\": \"Hewlett -Packard\",\n      \"is_top_tier\": \"No\",\n      \"reason\": \"Not in the leagues of Meta, Apple, Netflix, Google, Microsoft. Got: Expecting ',' delimiter: line 19 column 6 (char 585)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4by0pVfWy_W",
        "outputId": "934bc4d5-06af-4ae1-8cdb-d8ab29f8aab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Stars(STAR_INSTITUTION={'Madras University, Chennai': Institution(name='Madras University, Chennai', reason='None')}, STAR_EMPLOYERS={'Alten Calsoftlabs': Institution(name='Alten Calsoftlabs', reason='None'), 'Third ware': Institution(name='Third ware', reason='None'), 'Hewlett -Packard': Institution(name='Hewlett -Packard', reason='None'), 'TCS': Institution(name='TCS', reason='None'), 'Virtusa': Institution(name='Virtusa', reason='None'), 'Satyam': Institution(name='Satyam', reason='None')})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Given a list of educational institution and organizations identify top tier educational institution and top tier organization\n",
        "A top tier company should be a company in the leagues of Meta, Apple, Netflix, Google, Microsoft or Testla\n",
        "A top tier educational institute should be in the leagues of IIT and IIM.\n",
        "Only top tiers should be included in the output DO NOT INCLUDE non top tiers\n",
        "\n",
        "{institutions}\n",
        "\n",
        "The output should be a markdown code snippet formatted as a JSON instance that conforms to the JSON schema below, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"STAR_INSTITUTION\": Object [{{\"Top Tier Institute 1\":\"Reason Why it can be considered as top tier\"}},{{\"Top Tier Institute 2\":\"Reason Why it can be considered as top tier\"}}]  // A list of only top tier educational institutions\n",
        "  \"STAR_EMPLOYERS\": Object [{{\"Top Tier Company 1\":\"Reason Why it can be considered as top tier\"}},{{\"Top Tier Company 2\":\"Reason Why it can be considered as top tier\"}}]  // A list of only top tier companies\n",
        "}}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"institutions\"])\n",
        "\n",
        "intelligent_llm_chain = LLMChain(prompt=prompt, llm=choice_of_llm)\n",
        "all_known_institutes = \"\"\" \"LIST_OF_EDUCATION\": [\"Madras University, Chennai\"],\n",
        "  \"LIST_OF_EMPLOYERS\": [\"Alten Calsoftlabs\",\n",
        "                       \"Third ware\",\n",
        "                       \"Hewlett -Packard\",\n",
        "                       \"TCS\",\n",
        "                       \"Virtusa\",\n",
        "                       \"Satyam\"] \"\"\"\n",
        "result_2 = intelligent_llm_chain.run(all_known_institutes)\n",
        "#print(result_2)\n",
        "if \"```json\" in result_2:\n",
        "  print(\"formatting 2\")\n",
        "  json_string_2 = result_2.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "  #print(json_string_2)\n",
        "  structured_output_2=json.loads(json_string_2)\n",
        "  print(structured_output_2)\n",
        "else:\n",
        "  json_string_2 = result_2\n",
        "  print(\"gone\")\n",
        "  print(json_string_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2tsI6eJdS3n",
        "outputId": "90a3b49e-3cb9-45f2-95d1-889238bb9a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting 2\n",
            "{'STAR_INSTITUTION': [{'IIT': 'It is one of the top tier institutes in India'}], 'STAR_EMPLOYERS': [{'Apple': 'It is one of the top tier companies in the world'}, {'Google': 'It is one of the top tier companies in the world'}, {'Microsoft': 'It is one of the top tier companies in the world'}, {'Tesla': 'It is one of the top tier companies in the world'}, {'Netflix': 'It is one of the top tier companies in the world'}, {'Meta': 'It is one of the top tier companies in the world'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "main_query = \"\"\"\n",
        "from the given list of educational institution identify if anything is a top tier educational institution\n",
        "Assuming a top tier educational institute should be in the leagues of IIT and IIM.\n",
        "Only top tiers should be included in the output DO NOT INCLUDE non top tiers\n",
        "{question}\n",
        "\"LIST_OF_EDUCATION\": [\"MIT Massechusets\",BITS Pilani,\"Deakin Business School\",\"Cambridge University\"]\n",
        "\n",
        "The output should be a markdown code snippet formatted as a JSON instance that conforms to the JSON schema below, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"STAR_INSTITUTION\": Object [{{\"Top Tier Institute Name\":\"Reason\" }}]  // A list of only top tier educational institutions and reason\n",
        "}}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "chatopenai = ChatOpenAI(\n",
        "                model_name=\"gpt-3.5-turbo\",\n",
        "                openai_api_key=OPENAI_API_KEY,\n",
        "                temperature=0.0)\n",
        "prompt = PromptTemplate(template=main_query, input_variables=[\"question\"])\n",
        "llm_chain = LLMChain(prompt=prompt, llm=chatopenai)\n",
        "llm_chain.run(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "7sPJhWZQRGVm",
        "outputId": "8239f683-d101-4549-8ae0-6cb7107b4e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```json\\n{\\n  \"STAR_INSTITUTION\": [\\n    {\\n      \"Top Tier Institute Name\": \"MIT Massechusets\",\\n      \"Reason\": \"In the league of IIT and IIM\"\\n    },\\n    {\\n      \"Top Tier Institute Name\": \"Cambridge University\",\\n      \"Reason\": \"In the league of IIT and IIM\"\\n    }\\n  ]\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "star_check = academic_professional_stardom()\n",
        "pprint.pprint(star_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zUp6KZdEFq2",
        "outputId": "128c4ced-afff-4e9f-e24f-9174612acf0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "formatting 2\n",
            "{'LIST_OF_EDUCATION': ['Madras University, Chennai'],\n",
            " 'LIST_OF_EMPLOYERS': ['Alten Calsoftlabs',\n",
            "                       'Third ware',\n",
            "                       'Hewlett -Packard',\n",
            "                       'TCS',\n",
            "                       'Virtusa',\n",
            "                       'Satyam']}\n",
            "{'STAR_EMPLOYERS': {'None': 'None'},\n",
            " 'STAR_INSTITUTION': {'Madras University, Chennai': 'Reason'}}\n",
            "{'LIST_OF_EDUCATION': ['Madras University, Chennai'],\n",
            " 'LIST_OF_EMPLOYERS': ['Alten Calsoftlabs',\n",
            "                       'Third ware',\n",
            "                       'Hewlett -Packard',\n",
            "                       'TCS',\n",
            "                       'Virtusa',\n",
            "                       'Satyam'],\n",
            " 'STAR_EMPLOYERS': {'None': 'None'},\n",
            " 'STAR_INSTITUTION': {'Madras University, Chennai': 'Reason'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skills_1 = get_all_skills(\"Java developer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc1NMmVH8qTb",
        "outputId": "e6b8fae3-5de6-41c5-da12-a96f3481aa46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "{\n",
            "    \"PROGRAMMING_LANGUAGES\": [\"Java\", \"Struts\", \"Ajax\", \"iBatis\", \"JSF\", \"REST/JSON Web services\", \"Spring\", \"AngularJS\", \"SOAP Web services\", \"Ford framework for Java\", \"EJB\"],\n",
            "    \"SDEs/IDEs\": [\"Eclipse\", \"Visual Studio\", \"IntelliJ IDEA\", \"Anypoint studio 7.6\", \"Github\", \"Go Pipelines\"],\n",
            "    \"DOMAINS\": [\"Banking and Finance\", \"Finance\", \"Automobile\"],\n",
            "    \"DATABASES\": [\"Oracle 10g\", \"Oracle 11i\", \"DB2\", \"MySQL\", \"MongoDB\", \"Neo4J\"]\n",
            "}\n",
            "\n",
            "{'DATABASES': ['Oracle 10g', 'Oracle 11i', 'DB2', 'MySQL', 'MongoDB', 'Neo4J'],\n",
            " 'DOMAINS': ['Banking and Finance', 'Finance', 'Automobile'],\n",
            " 'PROGRAMMING_LANGUAGES': ['Java',\n",
            "                           'Struts',\n",
            "                           'Ajax',\n",
            "                           'iBatis',\n",
            "                           'JSF',\n",
            "                           'REST/JSON Web services',\n",
            "                           'Spring',\n",
            "                           'AngularJS',\n",
            "                           'SOAP Web services',\n",
            "                           'Ford framework for Java',\n",
            "                           'EJB'],\n",
            " 'SDEs/IDEs': ['Eclipse',\n",
            "               'Visual Studio',\n",
            "               'IntelliJ IDEA',\n",
            "               'Anypoint studio 7.6',\n",
            "               'Github',\n",
            "               'Go Pipelines']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skills_2 = get_all_skills_with_yoe(\"Java developer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "6Iu3Dvou8w8w",
        "outputId": "ebf06362-5b8f-4305-c8dc-dc6cb9055215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "{\n",
            "    \"PROGRAMMING_LANGUAGES\": {\"Java\":12.5, \"Struts\":2.5, \"Ajax\":1, \"ibatis\":1, \"JSF\":1, \"REST/JSON\":1, \"Spring\":2.5, \"AngularJS\":1, \"Ford framework for Java\":2, \"Mule 3x/4x runtime\":2, \"Oracle\":3, \"Hibernate\":2, \"Gradle\":1, \"Jenkins\":1}, \n",
            "    \"SDEs/IDEs\": {\"Eclipse\":3.5, \"Visual Studio\":0, \"IntelliJ IDEA\":1, \"Anypoint studio 7.6\":1, \"Github\":2, \"Go Pipelines\":1, \"Sonargraph\":1, \"SonarQube\":1, \"FindBugs\":1},\n",
            "    \"DOMAINS\": {\"Banking and Finance\":1, \"Finance\":1.5, \"Automobile\":4.5},\n",
            "    \"DATABASES\": {\"Oracle 10g\":2.5, \"Oracle 11i\":2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5e3d717223fa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mskills_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_skills_with_yoe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java developer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-1cb6ee08c633>\u001b[0m in \u001b[0;36mget_all_skills_with_yoe\u001b[0;34m(given_role)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mjson_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"```json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"```\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mstructured_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mjson_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 5 column 51 (char 538)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_level = get_top_level_details(Check_role = \"Java Developer\")"
      ],
      "metadata": {
        "id": "Y9b6VA-auEmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9fb309-8fc9-4629-c901-acfbcbcc8aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n",
            "formatting\n",
            "{\n",
            "    \"SCORE_FOR_JAVA_DEVELOPER\": \"90\",\n",
            "    \"OTHER_SUITABLE_ROLES\": [\"Technical Lead\", \"Technical Analyst\", \"Architect\"],\n",
            "    \"TOP_SUITABLE_ROLES\": {\"Architect\": \"95\"}\n",
            "}\n",
            "\n",
            "{'OTHER_SUITABLE_ROLES': ['Technical Lead', 'Technical Analyst', 'Architect'],\n",
            " 'SCORE_FOR_JAVA_DEVELOPER': '90',\n",
            " 'TOP_SUITABLE_ROLES': {'Architect': '95'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = read_a_random_resume(main_folder_path=\"/content/drive/MyDrive/Resume Ranking\",idx=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9p6MzuzoHG7",
        "outputId": "22ba6964-e052-44a1-f747-f702d2a5b239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"PROGRAMMING_LANGUAGES\": list  // A list of all the programming languages example: Java, Python, C++, and JavaScript\n",
        "  \"SDEs/IDEs\": list // A list of all the software development environment(IDEs) example: Eclipse, Visual Studio, and IntelliJ IDEA\n",
        "  \"DOMAINS\": list // A list of various industries/domain consolidate if possible (ex banking, Finance into BFSI) example: Healthcare,Retail and Finance\n",
        "  \"DATABASES\": list // A list of various databases Check only for popular known databases example: MySQL, MongoDB and Neo4J\n",
        "}}\n",
        "```\"\"\"\n",
        "#  \"HIGHEST_DESIGNATION\": string // highest designation he has worked as\n",
        "#  \"IS_DOWNGRADE\": String // is Java developer role lower compared to Architect role\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "query=\"\"\"What are all the programming languages he/she is aware of\n",
        "      what are all the software development environment(IDEs) he/she has used\n",
        "      What are the various industries/domain he has worked on\n",
        "      What are the various well known databases he has worked on\n",
        "      \"\"\"\n",
        "#      What is his highest designation he has worked as\n",
        "#      Is \"\"\"+Check_role+\"\"\" designation lower than Architect according to corporate designation ladder give reasons\n",
        "\n",
        "result = qa.run(query)\n",
        "#print(result)\n",
        "#print(type(result))\n",
        "if \"```json\" in result:\n",
        "  print(\"formatting\")\n",
        "  json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "  print(json_string)\n",
        "  structured_output=json.loads(json_string)\n",
        "else:\n",
        "  json_string = result\n",
        "\n",
        "pprint.pprint(structured_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZg2ZLigiPfU",
        "outputId": "ed0f9ca2-e0df-4f9c-8963-2fac8ae02652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "{\n",
            "  \"PROGRAMMING_LANGUAGES\": [\"Java\", \"Python\", \"C++\", \"JavaScript\", \"Struts\", \"Ajax\", \"iBatis\", \"Jsf\", \"Spring\", \"AngularJS\", \"REST/JSON Web services\", \"Hibernate\"],\n",
            "  \"SDEs/IDEs\": [\"Eclipse\", \"Visual Studio\", \"IntelliJ IDEA\", \"Sonargraph\", \"SonarQube\", \"FindBugs\", \"Github\", \"Gradle\", \"Jenkins\"],\n",
            "  \"DOMAINS\": [\"Banking and Finance\", \"Finance\", \"Automobile\"],\n",
            "  \"DATABASES\": [\"Oracle 10g\", \"Oracle 11i\", \"Windows XP\", \"Unix\", \"MySQL\", \"MongoDB\", \"Neo4J\"]\n",
            "}\n",
            "\n",
            "{'DATABASES': ['Oracle 10g',\n",
            "               'Oracle 11i',\n",
            "               'Windows XP',\n",
            "               'Unix',\n",
            "               'MySQL',\n",
            "               'MongoDB',\n",
            "               'Neo4J'],\n",
            " 'DOMAINS': ['Banking and Finance', 'Finance', 'Automobile'],\n",
            " 'PROGRAMMING_LANGUAGES': ['Java',\n",
            "                           'Python',\n",
            "                           'C++',\n",
            "                           'JavaScript',\n",
            "                           'Struts',\n",
            "                           'Ajax',\n",
            "                           'iBatis',\n",
            "                           'Jsf',\n",
            "                           'Spring',\n",
            "                           'AngularJS',\n",
            "                           'REST/JSON Web services',\n",
            "                           'Hibernate'],\n",
            " 'SDEs/IDEs': ['Eclipse',\n",
            "               'Visual Studio',\n",
            "               'IntelliJ IDEA',\n",
            "               'Sonargraph',\n",
            "               'SonarQube',\n",
            "               'FindBugs',\n",
            "               'Github',\n",
            "               'Gradle',\n",
            "               'Jenkins']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"CURRENT_EMPLOYMENT\": string  // A company name indicating where is the candidate currently working\n",
        "  \"START_DATE\": date // Date in MMM-YYYY format showing when he started working with his current employment\n",
        "  \"STAY\": string // total years and months elapsed since START_DATE till July 2023\n",
        "  \"WAS_JOB_HOPPER\": string // yes or no whether he has showed tendency of job hopping in the past\n",
        "  \"JOB_HOPPER_CONSIDERATIONS\": string // Define why he is or is not a Job Hopper\n",
        "  \"CANDIDATE_NAME\": string // The name of the candidate\n",
        "}}\n",
        "```\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "query=\"\"\"where is he working currently\n",
        "      What is the start date of his current employment\n",
        "      What is the time elapsed since his start date Assuming today is 10 July 2023\n",
        "      Was he a job hopper in the past\n",
        "      Give reasons for job hopper considerations\n",
        "      what is the name of the candidate\n",
        "      \"\"\"\n",
        "\n",
        "result = qa.run(query)\n",
        "#print(result)\n",
        "#print(type(result))\n",
        "if \"```json\" in result:\n",
        "  print(\"formatting\")\n",
        "  json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "  print(json_string)\n",
        "  structured_output=json.loads(json_string)\n",
        "else:\n",
        "  json_string = result\n",
        "\n",
        "pprint.pprint(structured_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCRBrrI0rVXR",
        "outputId": "f74d7a2a-436d-4a7d-c5e3-65c1f260d491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formatting\n",
            "{\n",
            "  \"CURRENT_EMPLOYMENT\": \"Alten Calsoftlabs\",\n",
            "  \"START_DATE\": \"Nov-2018\",\n",
            "  \"STAY\": \"4 years and 8 months\",\n",
            "  \"WAS_JOB_HOPPER\": \"No\",\n",
            "  \"JOB_HOPPER_CONSIDERATIONS\": \"The candidate has worked with the same employer for 4 years and 8 months, which is a long period of time.\",\n",
            "  \"CANDIDATE_NAME\": \"Thyagarajan Gnanasekaran\"\n",
            "}\n",
            "\n",
            "{'CANDIDATE_NAME': 'Thyagarajan Gnanasekaran',\n",
            " 'CURRENT_EMPLOYMENT': 'Alten Calsoftlabs',\n",
            " 'JOB_HOPPER_CONSIDERATIONS': 'The candidate has worked with the same employer '\n",
            "                              'for 4 years and 8 months, which is a long '\n",
            "                              'period of time.',\n",
            " 'START_DATE': 'Nov-2018',\n",
            " 'STAY': '4 years and 8 months',\n",
            " 'WAS_JOB_HOPPER': 'No'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "```json\n",
        "{{\n",
        "  \"LIST_OF_EDUCATION\": list  // A list of educational institutions\n",
        "  \"LIST_OF_EMPLOYERS\": list // A list of companies\n",
        "}}\n",
        "```\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "choice_of_llm = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "qa = RetrievalQA.from_chain_type(llm=choice_of_llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
        "query=\"\"\"what are all the educational institution he has studied in\n",
        "         What are all the companies he has worked at\n",
        "      \"\"\"\n",
        "     #       Is any of these institution Top tier or premium institute\n",
        "\n",
        "     # Is there any top tier company he has worked at\n",
        "\n",
        "#      What is his highest designation he has worked as\n",
        "#      Is \"\"\"+Check_role+\"\"\" designation lower than Architect according to corporate designation ladder give reasons\n",
        "\n",
        "result = qa.run(query)\n",
        "print(result)\n",
        "#print(type(result))\n",
        "if \"```json\" in result:\n",
        "  print(\"formatting\")\n",
        "  json_string = result.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "  #print(json_string)\n",
        "  template = \"\"\" Given a list of educational institution and organizations identify top tier educational institution and top tier organization\n",
        "  A top tier company should be a company in the leagues of Meta, Apple, Netflix, Google, Microsoft or Testla\n",
        "  A top tier educational institute should be in the leagues of IIT and IIM.\n",
        "  If there is None answer None in the corresponding output\n",
        "\n",
        "  {question}\n",
        "\n",
        "  The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "  ```json\n",
        "  {{\n",
        "    \"STAR_INSTITUTION\": {{\"Company\":\"Reason\"}} // key is the company names and value is the reason why it is top tier if none then give None\n",
        "    \"STAR_EMPLOYERS\": {{\"Institution\":\"Reason\"}} // key is the institution name and value is the reason why it is top tier if none then give None\n",
        "  }}\"\"\"\n",
        "\n",
        "  prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "  intelligent_llm_chain = LLMChain(prompt=prompt, llm=choice_of_llm)\n",
        "  structured_output=json.loads(json_string)\n",
        "  result_2 = intelligent_llm_chain.run(json_string)\n",
        "  #print(result_2)\n",
        "  if \"```json\" in result_2:\n",
        "    print(\"formatting 2\")\n",
        "    json_string_2 = result_2.split(\"```json\")[1].strip().replace(\"```\",\"\")\n",
        "    print(json_string_2)\n",
        "    structured_output_2=json.loads(json_string_2)\n",
        "  else:\n",
        "    json_string_2 = result_2\n",
        "else:\n",
        "  json_string = result\n",
        "\n",
        "pprint.pprint(structured_output)\n",
        "pprint.pprint(structured_output_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljrjqNFAKJ9f",
        "outputId": "8966b164-dd5c-4f8b-fee0-09a1fc2b01f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"LIST_OF_EDUCATION\": [\"Madras University, Chennai\"],\n",
            "  \"LIST_OF_EMPLOYERS\": [\"Alten Calsoftlabs\", \"Third ware\", \"Hewlett -Packard\", \"TCS\", \"Virtusa\", \"Satyam\"]\n",
            "}\n",
            "```\n",
            "formatting\n",
            "formatting 2\n",
            "{\n",
            "  \"STAR_INSTITUTION\": \"None\",\n",
            "  \"STAR_EMPLOYERS\": \"None\"\n",
            "}\n",
            "\n",
            "{'LIST_OF_EDUCATION': ['Madras University, Chennai'],\n",
            " 'LIST_OF_EMPLOYERS': ['Alten Calsoftlabs',\n",
            "                       'Third ware',\n",
            "                       'Hewlett -Packard',\n",
            "                       'TCS',\n",
            "                       'Virtusa',\n",
            "                       'Satyam']}\n",
            "{'STAR_EMPLOYERS': 'None', 'STAR_INSTITUTION': 'None'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "# Choice of chain\n",
        "#from langchain.chains import RetrievalQA\n",
        "#from langchain.chains import VectorDBQA\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "role_checking = \"Java Developer\"\n",
        "\n",
        "openaikey = \"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = openaikey\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "chat_model = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"POTENTIAL_ROLES\", description=\"Based on the various skills the candidate has what are the potential roles he will be suitable along with a score for each of these roles out of 100\"),\n",
        "    ResponseSchema(name=\"SCORE_FOR_\"+role_checking.replace(\" \",\"_\").upper(), description=\"scoring for the candidate for \"+role_checking),\n",
        "    ResponseSchema(name=\"REASON_FOR_TOP_ROLE\", description=\"based on potential roles which role is the most superior role and why is the candidate fit for that role\")\n",
        "]\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(output_parser.get_format_instructions())\n",
        "\n",
        "template = \"\"\"\n",
        "Based on the various skills the candidate has what are the potential roles\n",
        "he will be suitable along with a score for each of these roles out of 100, Also provide valid reason for a the highest possible role.\n",
        "also give scoring for the candidate for the given input role.\n",
        "\n",
        "Candidate role INPUT:\n",
        "{given_role}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Wrap your final output with closed and open brackets (a list of json objects)\n",
        "\n",
        "YOUR RESPONSE:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"given_role\"],\n",
        "    partial_variables={\"format_instructions\":format_instructions}\n",
        ")\n",
        "\n",
        "_input = prompt.format_prompt(given_role=role_checking)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehapxlQTJBfn",
        "outputId": "1cdf7eee-13ec-42e6-85cb-a6478e1066db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"POTENTIAL_ROLES\": string  // Based on the various skills the candidate has what are the potential roles he will be suitable along with a score for each of these roles out of 100\n",
            "\t\"SCORE_FOR_JAVA_DEVELOPER\": string  // scoring for the candidate for Java Developer\n",
            "\t\"REASON_FOR_TOP_ROLE\": string  // based on potential roles which role is the most superior role and why is the candidate fit for that role\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = OpenAI(model_name='text-davinci-003', temperature=0.0, openai_api_key=OPENAI_API_KEY)\n",
        "output = model(_input.to_string())"
      ],
      "metadata": {
        "id": "XxD6uA98U587"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_input.to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5f8qijPJ1Tc",
        "outputId": "8b1314e6-c1f1-427e-afe6-08b307e45fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='\\nBased on the various skills the candidate has what are the potential roles\\nhe will be suitable along with a score for each of these roles out of 100, Also provide valid reason for a the highest possible role.\\nalso give scoring for the candidate for the given input role.\\n\\nCandidate role INPUT: \\nJava Developer\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"POTENTIAL_ROLES\": string  // Based on the various skills the candidate has what are the potential roles he will be suitable along with a score for each of these roles out of 100\\n\\t\"SCORE_FOR_JAVA_DEVELOPER\": string  // scoring for the candidate for Java Developer\\n\\t\"REASON_FOR_TOP_ROLE\": string  // based on potential roles which role is the most superior role and why is the candidate fit for that role\\n}\\n```\\n\\nWrap your final output with closed and open brackets (a list of json objects)\\n\\nYOUR RESPONSE:\\n', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "chatbot = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(\n",
        "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "    temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=500\n",
        "    ),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever()\n",
        "    )\n",
        "\n",
        "print(chatbot.run(\n",
        "prompt.format(query=_input.to_messages())\n",
        "))"
      ],
      "metadata": {
        "id": "lbIRx4PESSnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "          chat_model,\n",
        "          db.as_retriever())\n",
        "\n",
        "l_qa = load_qa_chain(\n",
        "          llm = OpenAI(openai_api_key=OPENAI_API_KEY,\n",
        "                 temperature=0),\n",
        "          chain_type = \"stuff\")\n",
        "\n",
        "def answer_lqa(query):\n",
        "  docsearch = db.as_retriever()\n",
        "  docs = docsearch.get_relevant_documents(query)\n",
        "  result = l_qa.run(input_documents=docs, question = query)\n",
        "  return result\n",
        "\n",
        "def answer_conv():\n",
        "  chat_history =  []\n",
        "  result = qa({\"question\": _input.to_messages(), \"chat_history\": chat_history})\n",
        "  #print(result)\n",
        "  return result"
      ],
      "metadata": {
        "id": "nGJddaPjJPwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choice of LLM\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "# Choice of chain\n",
        "#from langchain.chains import RetrievalQA\n",
        "#from langchain.chains import VectorDBQA\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "role_checking = \"Java Developer\"\n",
        "\n",
        "openaikey = \"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = openaikey\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "chat_model = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"POTENTIAL_ROLES\", description=\"Based on the various skills the candidate has what are the potential roles he will be suitable along with a score for each of these roles out of 100\"),\n",
        "    ResponseSchema(name=\"SCORE_FOR_\"+role_checking.replace(\" \",\"_\").upper(), description=\"scoring for the candidate for \"+role_checking),\n",
        "    ResponseSchema(name=\"REASON_FOR_TOP_ROLE\", description=\"based on potential roles which role is the most superior role and why is the candidate fit for that role\")\n",
        "]\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(output_parser.get_format_instructions())\n",
        "\n",
        "template = \"\"\"\n",
        "Based on the various skills the candidate has what are the potential roles\n",
        "he will be suitable along with a score for each of these roles out of 100, Also provide valid reason for a the highest possible role.\n",
        "also give scoring for the candidate for the given input role.\n",
        "\n",
        "Candidate role INPUT:\n",
        "{given_role}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Wrap your final output with closed and open brackets (a list of json objects)\n",
        "\n",
        "YOUR RESPONSE:\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        HumanMessagePromptTemplate.from_template(template)\n",
        "    ],\n",
        "    input_variables=[\"given_role\"]\n",
        "    partial_variables={\"format_instructions\":format_instructions}\n",
        ")\n",
        "\n",
        "_input = prompt.format_prompt()\n",
        "print(_input.messages[0].content)\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "          chat_model,\n",
        "          db.as_retriever())\n",
        "\n",
        "l_qa = load_qa_chain(\n",
        "          llm = OpenAI(openai_api_key=OPENAI_API_KEY,\n",
        "                 temperature=0),\n",
        "          chain_type = \"stuff\")\n",
        "\n",
        "def answer_lqa(query):\n",
        "  docsearch = db.as_retriever()\n",
        "  docs = docsearch.get_relevant_documents(query)\n",
        "  result = l_qa.run(input_documents=docs, question = query)\n",
        "  return result\n",
        "\n",
        "def answer_conv():\n",
        "  chat_history =  []\n",
        "  result = qa({\"question\": _input.to_messages(), \"chat_history\": chat_history})\n",
        "  #print(result)\n",
        "  return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0HUTqeUvI90",
        "outputId": "e8bece0b-0903-4493-cd23-82bc5122ca7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"POTENTIAL_ROLES\": string  // Based on the various skills the candidate has what are the potential roles he will be suitable along with a score for each of these roles out of 100\n",
            "\t\"SCORE_FOR_JAVA_DEVELOPER\": string  // scoring for the candidate for Java Developer\n",
            "\t\"REASON_FOR_TOP_ROLE\": string  // based on potential roles which role is the most superior role and why is the candidate fit for that role\n",
            "}\n",
            "```\n",
            "\n",
            "Based on the various skills the candidate has what are the potential roles\n",
            "he will be suitable along with a score for each of these roles out of 100, Also provide valid reason for a the highest possible role.\n",
            "also give scoring for the candidate for Java Developer.\n",
            "\n",
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"POTENTIAL_ROLES\": string  // Based on the various skills the candidate has what are the potential roles he will be suitable along with a score for each of these roles out of 100\n",
            "\t\"SCORE_FOR_JAVA_DEVELOPER\": string  // scoring for the candidate for Java Developer\n",
            "\t\"REASON_FOR_TOP_ROLE\": string  // based on potential roles which role is the most superior role and why is the candidate fit for that role\n",
            "}\n",
            "```\n",
            "\n",
            "Wrap your final output with closed and open brackets (a list of json objects)\n",
            "\n",
            "YOUR RESPONSE:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = answer_conv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "xBl5mM_42k_B",
        "outputId": "eae026f8-dc53-4938-8eaf-89b89275f704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-18a7d5e0ab23>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-1028b737ef97>\u001b[0m in \u001b[0;36manswer_conv\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manswer_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0mchat_history\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"chat_history\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchat_history\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;31m#print(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             outputs = (\n\u001b[0;32m--> 237\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/conversational_retrieval/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_question\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_question\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/conversational_retrieval/base.py\u001b[0m in \u001b[0;36m_get_docs\u001b[0;34m(self, question, inputs, run_manager)\u001b[0m\n\u001b[1;32m    285\u001b[0m     ) -> List[Document]:\n\u001b[1;32m    286\u001b[0m         \u001b[0;34m\"\"\"Get docs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         docs = self.retriever.get_relevant_documents(\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/retriever.py\u001b[0m in \u001b[0;36mget_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_retriever_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             run_manager.on_retriever_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/retriever.py\u001b[0m in \u001b[0;36mget_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_other_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 result = self._get_relevant_documents(\n\u001b[0m\u001b[1;32m    175\u001b[0m                     \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/base.py\u001b[0m in \u001b[0;36m_get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    411\u001b[0m     ) -> List[Document]:\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"similarity\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"similarity_score_threshold\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             docs_and_similarities = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/faiss.py\u001b[0m in \u001b[0;36msimilarity_search\u001b[0;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mDocuments\u001b[0m \u001b[0mmost\u001b[0m \u001b[0msimilar\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m         docs_and_scores = self.similarity_search_with_score(\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/faiss.py\u001b[0m in \u001b[0;36msimilarity_search_with_score\u001b[0;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mL2\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mLower\u001b[0m \u001b[0mscore\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0mmore\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         docs = self.similarity_search_with_score_by_vector(\n\u001b[1;32m    260\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/embeddings/huggingface.py\u001b[0m in \u001b[0;36membed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \"\"\"\n\u001b[1;32m    170\u001b[0m         \u001b[0minstruction_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_instruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstruction_pair\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0mlength_sorted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_text_length\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m#Sum of length of individual strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     def fit(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m#Sum of length of individual strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     def fit(self,\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'HumanMessage' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = chat_model(_input.to_messages())\n",
        "print(type(output))\n",
        "print(output.content)"
      ],
      "metadata": {
        "id": "8L_cAYST0Mht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "query = \"\"\"Based on the various skills the candidate has what are the potential roles\n",
        "he will be suitable along with a score for each of these roles out of 100, Also provide valid reason for a the highest possible role.\n",
        "also give scoring for the candidate for \"\"\"+role_checking+\"\"\". Give the output as a python dictionary with the following as keys {POTENTIAL_ROLES, REASON_FOR_TOP_ROLE,SCORE_FOR\"\"\"+role_checking.replace(\"\",\"_\").upper()+\"\"\"\"\"\"\n",
        "print(query)\n",
        "print(\"\\n\\n\")\n",
        "result = answer_lqa(query)\n",
        "pprint(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoobLuUfvMCx",
        "outputId": "3e14b777-40cd-4196-a237-1a14016fba24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(' POTENTIAL_ROLES: Technical Lead (90/100), Architect (80/100), Technical '\n",
            " 'Analyst (70/100); REASON_FOR_TOP_ROLE: The candidate has extensive '\n",
            " 'experience in the banking and finance domain, and has worked as a Technical '\n",
            " 'Lead for a project involving Credit Risk Interface for Citi Bank, USA; '\n",
            " 'SCORE_FOR_JAVA_DEVELOPER: 80/100.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GpApxinwbd1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}